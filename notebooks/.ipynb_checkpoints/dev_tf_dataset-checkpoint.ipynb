{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'etl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01metl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatasetProcessor\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m target_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../test_files/TOGETHER\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'etl'"
     ]
    }
   ],
   "source": [
    "from etl.load_dataset import DatasetProcessor\n",
    "import matplotlib.pyplot as plt\n",
    "target_dir = '../test_files/TOGETHER'\n",
    "dp = DatasetProcessor(target_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "class DatasetProcessor:\n",
    "    def __init__(self, target_directory, image_extensions=('jpg'), annotation_extensions=('json'), id_prefix_size=10):\n",
    "        self.target_directory = target_directory\n",
    "        self.image_extensions = image_extensions\n",
    "        self.annotation_extension = annotation_extensions\n",
    "        # We assume that the patient id is encoded in the first id_prefix_size numbers of each file\n",
    "        self.id_prefix_size = id_prefix_size\n",
    "        self.dataset_dictionary = self._load_file_names()\n",
    "\n",
    "    def _load_file_names(self):\n",
    "        dataset_files = sorted(os.listdir(self.target_directory))\n",
    "        json_names = [x for x in dataset_files if x.endswith('.json')]\n",
    "        image_names = [x for x in dataset_files if x not in json_names]\n",
    "        patient_ids = np.array([x[:self.id_prefix_size] for x in json_names])\n",
    "        return {pid_: [[image_ for image_ in image_names if image_.startswith(pid_)],\n",
    "                       [json_ for json_ in json_names if json_.startswith(pid_)]] for pid_ in patient_ids}\n",
    "\n",
    "    # bbox, eggim in bbox, landmark\n",
    "    def process_json(self, directory):  # TODO: test this\n",
    "        with open(directory, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        dict_parameters = {}\n",
    "        for instance in data['instances']:\n",
    "            if instance['className'] == 'EGGIM in the FULL Anatomical Location':\n",
    "                dict_parameters['eggim_global'] = int(instance['attributes'][0]['name'])\n",
    "            if instance['className'] == 'EGGIM in Target Area - Square':\n",
    "                dict_parameters['eggim_square'] = int(instance['attributes'][0]['name'])\n",
    "            if instance['className'] == 'Anatomical Location':\n",
    "                dict_parameters['landmark'] = str(instance['attributes'][0]['name'])\n",
    "            if instance[\"type\"] == \"bbox\" and \"points\" in instance:\n",
    "                points = instance[\"points\"]\n",
    "                left = points[\"x1\"]\n",
    "                top = points[\"y1\"]\n",
    "                right = points[\"x2\"]\n",
    "                bottom = points[\"y2\"]\n",
    "                # print(\"x1\", left, \"y1\", top, \"x2\", right, \"y2\", bottom)\n",
    "                dict_parameters['bbox'] = np.array([math.floor(left), math.floor(top), math.floor(right), math.floor(bottom)]) # plt.imshow(np.array(image)[round(y1):round(y2), round(x1):round(x2), :])\n",
    "        return dict_parameters\n",
    "\n",
    "    def process(self):\n",
    "        dataset_info = []\n",
    "        for patient, (images, jsons) in self.dataset_dictionary.items():\n",
    "            for x, y in zip(images, jsons):\n",
    "                annotation_data = self.process_json(os.path.join(self.target_directory, y))\n",
    "                annotation_data['image_directory'] = os.path.join(self.target_directory, x)\n",
    "                dataset_info.append(annotation_data)\n",
    "        return pd.DataFrame(dataset_info)\n",
    "\n",
    "\n",
    "\n",
    "#dp.to_tf_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224 224 207 125\n",
      "224 225 268 144\n",
      "224 224 221 135\n",
      "223 224 226 216\n",
      "TensorShape([224, 224, 3])\n",
      "1\n",
      "TensorShape([224, 224, 3])\n",
      "2\n",
      "TensorShape([224, 224, 3])\n",
      "2\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "assertion failed: [height must be >= target + offset.]\n\t [[{{node crop_to_bounding_box/Assert_5/Assert}}]] [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 54\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Apply the preprocessing function to the dataset\u001b[39;00m\n\u001b[1;32m     52\u001b[0m dataset_processed \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m img, score, bbox: get_data(img, score, bbox), num_parallel_calls\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m dataset_processed:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# You can print the shapes or other details if needed\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     tf\u001b[38;5;241m.\u001b[39mprint(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     57\u001b[0m     tf\u001b[38;5;241m.\u001b[39mprint(y)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:766\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    765\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    767\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:749\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[0;32m--> 749\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    754\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    756\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3017\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3015\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3016\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 3017\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3018\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[1;32m   3019\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:7164\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7163\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7164\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: assertion failed: [height must be >= target + offset.]\n\t [[{{node crop_to_bounding_box/Assert_5/Assert}}]] [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "target_dir = '../test_files/TOGETHER'\n",
    "dp = DatasetProcessor(target_dir)\n",
    "file_df = dp.process()\n",
    "bboxes = np.stack(np.array(file_df['bbox'].values), axis=-1).T # yay!\n",
    "images = file_df['image_directory'].values\n",
    "eggim_square = file_df['eggim_square'].values\n",
    "\n",
    "\n",
    "image_class_np = np.vstack([images, eggim_square, np.array(file_df['bbox'].values)]).T\n",
    "\n",
    "# Assuming images, eggim_square, and bboxes are defined properly somewhere in your code.\n",
    "image_ds = tf.data.Dataset.from_tensor_slices(images)\n",
    "eggim_square_ds = tf.data.Dataset.from_tensor_slices(eggim_square)\n",
    "bboxes_ds = tf.data.Dataset.from_tensor_slices(bboxes)\n",
    "\n",
    "# Combine the datasets into a single dataset\n",
    "dataset = tf.data.Dataset.zip((image_ds, eggim_square_ds, bboxes_ds))\n",
    "\n",
    "def crop_image(image, bbox, crop_height=224, crop_width=224):\n",
    "    # tf.print(bbox)\n",
    "    # Calculate the height and width of the bounding box\n",
    "    bbox_height = tf.cast(bbox[2] - bbox[0], tf.int32)\n",
    "    bbox_width = tf.cast(bbox[3] - bbox[1], tf.int32)\n",
    "\n",
    "    # Calculate the offset for cropping\n",
    "    offset_height = tf.cast(bbox[0], tf.int32)\n",
    "    offset_width = tf.cast(bbox[1], tf.int32)\n",
    "    \n",
    "    tf.print(bbox_height, bbox_width, offset_height, offset_width)\n",
    "    \n",
    "    # Crop the image to the bounding box\n",
    "    cropped_image = tf.image.crop_to_bounding_box(image, offset_height, offset_width, bbox_height, bbox_width)\n",
    "\n",
    "    # Resize the cropped image to the desired size\n",
    "    resized_image = tf.image.resize(cropped_image, [crop_height, crop_width])\n",
    "    return resized_image\n",
    "\n",
    "def load_and_preprocess_image(image_path, bbox):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = crop_image(image, bbox)\n",
    "    return image\n",
    "\n",
    "def get_data(image_dir, eggim_square_score, bbox):\n",
    "    x = tf.cast(load_and_preprocess_image(image_dir, bbox), dtype=tf.float32)\n",
    "    y = tf.cast(eggim_square_score, dtype=tf.float32)\n",
    "    return x, y\n",
    "\n",
    "# Apply the preprocessing function to the dataset\n",
    "dataset_processed = dataset.map(lambda img, score, bbox: get_data(img, score, bbox), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "for x, y in dataset_processed:\n",
    "    # You can print the shapes or other details if needed\n",
    "    tf.print(x.shape)\n",
    "    tf.print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['../test_files/TOGETHER/20190927085204439.jpg.jpg',\n",
       "       '../test_files/TOGETHER/20190927113819624.jpg.jpg',\n",
       "       '../test_files/TOGETHER/20240117161144440.jpg',\n",
       "       '../test_files/TOGETHER/20240123103123152.jpg',\n",
       "       array([221, 136, 445, 360]), array([226, 216, 450, 441]),\n",
       "       array([207, 126, 431, 350]), array([268, 145, 492, 369])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([file_df['image_directory'], file_df['bbox']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def load_and_preprocess_image(image_path):\n",
    "        image = tf.io.read_file(image_path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        return image\n",
    "\n",
    "def get_data(file):\n",
    "    image, annotation = file[0], file[1]\n",
    "    x, y = load_and_preprocess_image(image), load_and_process_json(annotation)\n",
    "    print(x)\n",
    "    print(y)\n",
    "    x =  tf.keras.preprocessing.image.array_to_img(x)\n",
    "\n",
    "    cropped_image = x[bottom:top, left:right, :]\n",
    "    # 231.2\n",
    "    return cropped_image, y\n",
    "img_processed = tf.map_fn(load_and_preprocess_image, file_tensor[:, 0 ], dtype=tf.uint8)\n",
    "json_coords = tf.map_fn(load_and_process_json, file_tensor[:, 1], dtype=tf.float32)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(file_tensor)\n",
    "dataset.map(get_data, tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
