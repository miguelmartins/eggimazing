{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-15 10:41:04.882426: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-15 10:41:04.882486: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-15 10:41:04.882516: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-15 10:41:04.889538: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.metrics import Precision, Recall, AUC, CategoricalAccuracy\n",
    "\n",
    "from custom_models.augmentation import basic_plus_color_augmentation, basic_augmentation\n",
    "from custom_models.bilinear_cnns import fe_resnet\n",
    "from custom_models.cnns import simple_cnn_bn, base_resnet50\n",
    "from custom_models.optimization_utilities import get_standard_callbacks\n",
    "from etl.load_dataset import DatasetProcessor, get_tf_eggim_patch_dataset\n",
    "from optimization.custom_losses import weighted_categorical_crossentropy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'/home/miguelmartins/Projects/eggimazing/notebooks'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "target_dir = '../test_files/EGGIMazing/Dataset3'  # aqui foi o o que eu chamei no remote server, mas fica a criterio\n",
    "dp = DatasetProcessor(target_dir)\n",
    "df = dp.process()\n",
    "\n",
    "togas_ids_boolean = np.array([x.startswith('PT') for x in df['patient_id'].values])\n",
    "df_togas = df[togas_ids_boolean].reset_index(drop=True)\n",
    "df_ipo = df[~togas_ids_boolean].reset_index(drop=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "df = df_togas.copy()\n",
    "lands = [x.split('.')[0] for x in np.unique(df.landmark).squeeze()]\n",
    "p_ids = list(set(df['patient_id']))\n",
    "valid_patients = []\n",
    "for p_id in p_ids:\n",
    "    p_lands = np.unique(df[df.patient_id == p_ids[0]].landmark).squeeze()\n",
    "    p_lands = [x.split('.')[0] for x in p_lands]\n",
    "    if 'ii' in p_lands or 'xii' in p_lands:\n",
    "        if 'ix' in p_lands or 'x' in p_lands:\n",
    "            if 'vi' in p_lands and\\\n",
    "                'vii' in p_lands and\\\n",
    "                'viii' in p_lands:\n",
    "                valid_patients.append(p_id)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def get_valid_patiend_ids(dataframe):\n",
    "    df = dataframe.copy()\n",
    "    p_ids = list(set(df['patient_id']))\n",
    "    valid_patients = []\n",
    "    for p_id in p_ids:\n",
    "        p_lands = np.unique(df[df.patient_id == p_ids[0]].landmark).squeeze()\n",
    "        p_lands = [x.split('.')[0] for x in p_lands]\n",
    "        if 'ii' in p_lands or 'xii' in p_lands:\n",
    "            if 'ix' in p_lands or 'x' in p_lands:\n",
    "                if 'vi' in p_lands and\\\n",
    "                    'vii' in p_lands and\\\n",
    "                    'viii' in p_lands:\n",
    "                    valid_patients.append(p_id)\n",
    "    return p_lands\n",
    "\n",
    "valid_patients = get_valid_patiend_ids(df_togas)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "np.save('new_patient_ids.npy', valid_patients)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "debug_pids = ['PT004', 'PT005', 'PT006', 'PT009', 'PT016', 'PT020', 'PT021', 'PT022']\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 16:52:36.852108: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-08 16:52:36.852192: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-08 16:52:36.852224: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-08 16:52:36.861096: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from etl.load_dataset import DatasetProcessor, get_tf_eggim_patch_dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "                     bbox  eggim_global  eggim_square  \\\n0    [218, 113, 442, 338]           0.0           0.0   \n1    [213, 228, 438, 452]           0.0           0.0   \n2    [190, 231, 415, 455]           0.0           0.0   \n3    [208, 235, 432, 460]           1.0           0.0   \n4    [314, 153, 539, 378]           0.0           0.0   \n..                    ...           ...           ...   \n862  [328, 212, 552, 436]           0.0           0.0   \n863  [323, 178, 547, 403]           0.0           0.0   \n864  [277, 140, 501, 364]           1.0           1.0   \n865  [262, 161, 486, 386]           2.0           2.0   \n866  [232, 106, 456, 330]           1.0           1.0   \n\n                                              landmark  \\\n0                       ii. distal body in anteversion   \n1          ix. distal lesser curvature in retroflexion   \n2          ix. distal lesser curvature in retroflexion   \n3                        x. upper body in retroflexion   \n4    vii. proximal antrum - greater curvature/poste...   \n..                                                 ...   \n862        ix. distal lesser curvature in retroflexion   \n863                      x. upper body in retroflexion   \n864                     viii. incisura in retroflexion   \n865  vii. proximal antrum - greater curvature/poste...   \n866             vi. proximal antrum - lesser curvature   \n\n                                       image_directory patient_id  \n0    ../test_files/EGGIMazing/Dataset3/202401171600...      PT002  \n1    ../test_files/EGGIMazing/Dataset3/202401171603...      PT002  \n2    ../test_files/EGGIMazing/Dataset3/202401171604...      PT002  \n3    ../test_files/EGGIMazing/Dataset3/202401171604...      PT002  \n4    ../test_files/EGGIMazing/Dataset3/202401191231...      PT003  \n..                                                 ...        ...  \n862  ../test_files/EGGIMazing/Dataset3/202410161824...      PT086  \n863  ../test_files/EGGIMazing/Dataset3/202410161824...      PT086  \n864  ../test_files/EGGIMazing/Dataset3/202410161827...      PT086  \n865  ../test_files/EGGIMazing/Dataset3/202410161827...      PT086  \n866  ../test_files/EGGIMazing/Dataset3/202410161828...      PT086  \n\n[867 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bbox</th>\n      <th>eggim_global</th>\n      <th>eggim_square</th>\n      <th>landmark</th>\n      <th>image_directory</th>\n      <th>patient_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[218, 113, 442, 338]</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>ii. distal body in anteversion</td>\n      <td>../test_files/EGGIMazing/Dataset3/202401171600...</td>\n      <td>PT002</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[213, 228, 438, 452]</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>ix. distal lesser curvature in retroflexion</td>\n      <td>../test_files/EGGIMazing/Dataset3/202401171603...</td>\n      <td>PT002</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[190, 231, 415, 455]</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>ix. distal lesser curvature in retroflexion</td>\n      <td>../test_files/EGGIMazing/Dataset3/202401171604...</td>\n      <td>PT002</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[208, 235, 432, 460]</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>x. upper body in retroflexion</td>\n      <td>../test_files/EGGIMazing/Dataset3/202401171604...</td>\n      <td>PT002</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[314, 153, 539, 378]</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>vii. proximal antrum - greater curvature/poste...</td>\n      <td>../test_files/EGGIMazing/Dataset3/202401191231...</td>\n      <td>PT003</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>862</th>\n      <td>[328, 212, 552, 436]</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>ix. distal lesser curvature in retroflexion</td>\n      <td>../test_files/EGGIMazing/Dataset3/202410161824...</td>\n      <td>PT086</td>\n    </tr>\n    <tr>\n      <th>863</th>\n      <td>[323, 178, 547, 403]</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>x. upper body in retroflexion</td>\n      <td>../test_files/EGGIMazing/Dataset3/202410161824...</td>\n      <td>PT086</td>\n    </tr>\n    <tr>\n      <th>864</th>\n      <td>[277, 140, 501, 364]</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>viii. incisura in retroflexion</td>\n      <td>../test_files/EGGIMazing/Dataset3/202410161827...</td>\n      <td>PT086</td>\n    </tr>\n    <tr>\n      <th>865</th>\n      <td>[262, 161, 486, 386]</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>vii. proximal antrum - greater curvature/poste...</td>\n      <td>../test_files/EGGIMazing/Dataset3/202410161827...</td>\n      <td>PT086</td>\n    </tr>\n    <tr>\n      <th>866</th>\n      <td>[232, 106, 456, 330]</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>vi. proximal antrum - lesser curvature</td>\n      <td>../test_files/EGGIMazing/Dataset3/202410161828...</td>\n      <td>PT086</td>\n    </tr>\n  </tbody>\n</table>\n<p>867 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_togas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 16:50:26.287556: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-08 16:50:26.287645: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-08 16:50:26.287677: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-08 16:50:26.296710: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GroupShuffleSplit, LeavePGroupsOut\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "class DatasetProcessor:\n",
    "    def __init__(self, target_directory, image_extensions=('jpg'), annotation_extensions=('json'), id_prefix_size=10):\n",
    "        self.target_directory = target_directory\n",
    "        self.image_extensions = image_extensions\n",
    "        self.annotation_extension = annotation_extensions\n",
    "        # We assume that the patient id is encoded in the first id_prefix_size numbers of each file\n",
    "        self.id_prefix_size = id_prefix_size\n",
    "        self.dataset_dictionary = self._load_file_names()\n",
    "\n",
    "    def _load_file_names(self):\n",
    "        dataset_files = sorted(os.listdir(self.target_directory))\n",
    "        json_names = [x for x in dataset_files if x.endswith('.json')]\n",
    "        image_names = [x for x in dataset_files if x not in json_names]\n",
    "        patient_ids = np.array([x[:self.id_prefix_size] for x in json_names])\n",
    "        return {pid_: [[image_ for image_ in image_names if image_.startswith(pid_)],\n",
    "                       [json_ for json_ in json_names if json_.startswith(pid_)]] for pid_ in patient_ids}\n",
    "\n",
    "    # bbox, eggim in bbox, landmark\n",
    "    def process_json(self, directory):\n",
    "        with open(directory, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        dict_parameters = {}\n",
    "        for instance in data['instances']:\n",
    "            if instance['className'] == 'EGGIM in the FULL Anatomical Location':\n",
    "                dict_parameters['eggim_global'] = int(instance['attributes'][0]['name'])\n",
    "            if instance['className'] == 'EGGIM in Target Area - Square':\n",
    "                dict_parameters['eggim_square'] = int(instance['attributes'][0]['name'])\n",
    "            if instance['className'] == 'Anatomical Location':\n",
    "                dict_parameters['landmark'] = str(instance['attributes'][0]['name'])\n",
    "            if instance['className'] == 'Comments':\n",
    "                if not instance['attributes']:  # check if list is empty\n",
    "                    continue\n",
    "                else:\n",
    "                    id_ = str(instance['attributes'][0]['name'])\n",
    "                    id_ = re.split(r'[ \\n]+', id_)[0]\n",
    "                    if id_.startswith('PT'):  # This is necessary to mark the patients from togas\n",
    "                        dict_parameters['patient_id'] = id_\n",
    "            if instance[\"type\"] == \"bbox\" and \"points\" in instance:\n",
    "                points = instance[\"points\"]\n",
    "                left = points[\"x1\"]\n",
    "                top = points[\"y1\"]\n",
    "                right = points[\"x2\"]\n",
    "                bottom = points[\"y2\"]\n",
    "                # print(\"x1\", left, \"y1\", top, \"x2\", right, \"y2\", bottom)\n",
    "                dict_parameters['bbox'] = np.array([math.floor(left), math.floor(top), math.floor(right), math.floor(\n",
    "                    bottom)])  # plt.imshow(np.array(image)[round(y1):round(y2), round(x1):round(x2), :])\n",
    "        return dict_parameters\n",
    "\n",
    "    def process(self, merge_eggim_square=False, merge_eggim_global=False):\n",
    "        dataset_info = []\n",
    "        for patient_id, (images, jsons) in self.dataset_dictionary.items():\n",
    "            for x, y in zip(images, jsons):\n",
    "                annotation_data = self.process_json(os.path.join(self.target_directory, y))\n",
    "                annotation_data['image_directory'] = os.path.join(self.target_directory, x)\n",
    "                if 'patient_id' not in annotation_data:\n",
    "                    annotation_data['patient_id'] = patient_id\n",
    "                dataset_info.append(annotation_data)\n",
    "        df = pd.DataFrame(dataset_info)\n",
    "        if merge_eggim_square:\n",
    "            df['eggim_square'] = df['eggim_square'].apply(lambda score: 0 if score == 0 else 1)\n",
    "        if merge_eggim_global:\n",
    "            df['eggim_global'] = df['eggim_global'].apply(lambda score: 0 if score == 0 else 1)\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def patient_wise_split(df_target,\n",
    "                           df_extra,\n",
    "                           patients_ids,\n",
    "                           internal_train_size=0.5,\n",
    "                           target_variable='eggim_square',\n",
    "                           random_state=None):\n",
    "\n",
    "        assert (0 < internal_train_size) and (internal_train_size < 1)\n",
    "        for patient_id in patients_ids:\n",
    "            test_frames_rows = df_target['patient_id'] == patient_id\n",
    "\n",
    "            df_test = df_target.loc[test_frames_rows]\n",
    "            df_temp = df_target.loc[~test_frames_rows]\n",
    "            X_temp = df_temp.drop(columns=[target_variable])\n",
    "            y_temp = df_temp[target_variable]\n",
    "            sss_temp = StratifiedShuffleSplit(n_splits=1, train_size=internal_train_size,\n",
    "                                              test_size=1. - internal_train_size, random_state=random_state)\n",
    "            train_idx, val_idx = next(sss_temp.split(X_temp, y_temp))\n",
    "\n",
    "            df_train = df_target.iloc[train_idx]\n",
    "            df_val = df_target.iloc[val_idx]\n",
    "            df_train = DatasetProcessor.augment_dataframe_stratified(df_train,\n",
    "                                                                     df_extra,\n",
    "                                                                     target_column=target_variable)\n",
    "            df_train = pd.concat([df_train, df_extra], axis=0)\n",
    "\n",
    "            yield df_train, df_val, df_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "target_dir = '../test_files/EGGIMazing/Dataset01'\n",
    "patient_ids = np.load('../configs/test_patient_ids_2.npy', allow_pickle=True)\n",
    "dp = DatasetProcessor(target_dir)\n",
    "df = dp.process()\n",
    "\n",
    "togas_ids_boolean = np.array([x.startswith('PT') for x in df['patient_id'].values])\n",
    "df_togas = df[togas_ids_boolean].reset_index(drop=True)\n",
    "df_ipo = df[~togas_ids_boolean].reset_index(drop=True)\n",
    "\n",
    "split = dp.patient_wise_split(df_togas,\n",
    "                              df_ipo,\n",
    "                              patient_ids,\n",
    "                              internal_train_size=0.9,\n",
    "                              target_variable='eggim_square',\n",
    "                              random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "bboxes = np.stack(np.array(df_togas['bbox'].values), axis=-1).T"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "pt04 = df_togas[df_togas['patient_id'] == 'PT004']\n",
    "pt24 = df_togas[df_togas['patient_id'] == 'PT024']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['PT002', 'PT003', 'PT004', 'PT005', 'PT006', 'PT007', 'PT008',\n       'PT009', 'PT010', 'PT011', 'PT012', 'PT013', 'PT014', 'PT015',\n       'PT016', 'PT017', 'PT018', 'PT019', 'PT020', 'PT021', 'PT022',\n       'PT023', 'PT024', 'PT025', 'PT026', 'PT027', 'PT028', 'PT029',\n       'PT030', 'PT031', 'PT032', 'PT034', 'PT035', 'PT036', 'PT037',\n       'PT038', 'PT039', 'PT040', 'PT041', 'PT042', 'PT043', 'PT044',\n       'PT045', 'PT046', 'PT047', 'PT048', 'PT049', 'PT050', 'PT051',\n       'PT052', 'PT053'], dtype=object)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_togas.patient_id)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 16:51:36.049270: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.049526: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.096861: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.097238: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.097449: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.097635: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.252618: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.252887: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.253098: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.253277: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.253452: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.253625: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.263712: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.263920: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.264116: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.264294: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.264475: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.264641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 18737 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-11-08 16:51:36.265373: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.265529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22453 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:02:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from etl.load_dataset import get_tf_eggim_patch_dataset\n",
    "import tensorflow as tf\n",
    "tf_test_df = get_tf_eggim_patch_dataset(pt24, num_classes=3,\n",
    "                                                preprocess_fn=tf.keras.applications.resnet.preprocess_input)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "patient_ids = np.load('../configs/test_patient_ids_2.npy', allow_pickle=True)\n",
    "split = dp.patient_wise_split(df_togas,\n",
    "                                  df_ipo,\n",
    "                                  patient_ids,\n",
    "                                  internal_train_size=0.9,\n",
    "                                  target_variable='eggim_square',\n",
    "                                  random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "for fold, (df_train, df_val, df_test) in enumerate(split):\n",
    "    if patient_ids[fold] == 'PT004':\n",
    "        pt04 = df_test\n",
    "    if patient_ids[fold] == 'PT024':"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "(8,)"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('../configs/test_patient_ids.npy', allow_pickle=True).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "(array(['PT004', 'PT005', 'PT006', 'PT009', 'PT016', 'PT020', 'PT021',\n        'PT022'], dtype=object),\n array(['PT004', 'PT005', 'PT006', 'PT009', 'PT016', 'PT020', 'PT021',\n        'PT022', 'PT024', 'PT025', 'PT028', 'PT029', 'PT030', 'PT031',\n        'PT034', 'PT035', 'PT037', 'PT039', 'PT040', 'PT041', 'PT045',\n        'PT046', 'PT048', 'PT049', 'PT051', 'PT053'], dtype=object))"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('../configs/test_patient_ids.npy', allow_pickle=True), np.load('../configs/test_patient_ids_2.npy', allow_pickle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
