{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-15 22:59:39.693055: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736981979.715771   93410 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736981979.720188   93410 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-15 22:59:39.748274: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.metrics import Precision, Recall, AUC, CategoricalAccuracy\n",
    "\n",
    "from custom_models.augmentation import basic_plus_color_augmentation, basic_augmentation\n",
    "from custom_models.bilinear_cnns import fe_resnet\n",
    "from custom_models.cnns import simple_cnn_bn, base_resnet50\n",
    "from custom_models.optimization_utilities import get_standard_callbacks\n",
    "from etl.load_dataset import DatasetProcessor, get_tf_eggim_patch_dataset\n",
    "from optimization.custom_losses import weighted_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/goda/Desktop/tese/eggimazing'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_dir = '../2025-01_EGGIM_Dataset3'  # aqui foi o o que eu chamei no remote server, mas fica a criterio\n",
    "dp = DatasetProcessor(target_dir)\n",
    "df = dp.process()\n",
    "\n",
    "togas_ids_boolean = np.array([x.startswith('PT') for x in df['patient_id'].values])\n",
    "df_togas = df[togas_ids_boolean].reset_index(drop=True)\n",
    "df_ipo = df[~togas_ids_boolean].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_valid_patiend_ids(dataframe):\n",
    "    df = dataframe.copy()\n",
    "    p_ids = list(set(df['patient_id']))\n",
    "    valid_patients = []\n",
    "    for p_id in p_ids:\n",
    "        p_lands = np.unique(df[df.patient_id == p_id].landmark).squeeze()\n",
    "        p_lands = [x.split('.')[0] for x in p_lands]\n",
    "\n",
    "        if 'ii' in p_lands or 'xii' in p_lands:\n",
    "            if 'ix' in p_lands or 'x' in p_lands:\n",
    "                if 'vi' in p_lands and\\\n",
    "                    'vii' in p_lands and\\\n",
    "                    'viii' in p_lands:\n",
    "                    valid_patients.append(p_id)\n",
    "    return valid_patients\n",
    "\n",
    "valid_patients = get_valid_patiend_ids(df_togas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save('configs/new_patient_ids.npy', valid_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PT053', 'PT016', 'PT049', 'PT074', 'PT045', 'PT081', 'PT004',\n",
       "       'PT030', 'PT082', 'PT050', 'PT072', 'PT068', 'PT028', 'PT083',\n",
       "       'PT037', 'PT084', 'PT070', 'PT034', 'PT060', 'PT015', 'PT067',\n",
       "       'PT005', 'PT078', 'PT032', 'PT009', 'PT035', 'PT073', 'PT061',\n",
       "       'PT051', 'PT041', 'PT075', 'PT013', 'PT077', 'PT063', 'PT039',\n",
       "       'PT011', 'PT023', 'PT048', 'PT031', 'PT086', 'PT047', 'PT071',\n",
       "       'PT040', 'PT076', 'PT064', 'PT029', 'PT066', 'PT021', 'PT054',\n",
       "       'PT069', 'PT026', 'PT043', 'PT006', 'PT065', 'PT080', 'PT024',\n",
       "       'PT025', 'PT038', 'PT022', 'PT062', 'PT079', 'PT020', 'PT036',\n",
       "       'PT046', 'PT059'], dtype='<U5')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('configs/new_patient_ids.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/goda/Desktop/tese/eggimazing\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "debug_pids = ['PT004', 'PT005', 'PT006', 'PT009', 'PT016', 'PT020', 'PT021', 'PT022']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from etl.load_dataset import DatasetProcessor, get_tf_eggim_patch_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bbox</th>\n",
       "      <th>eggim_global</th>\n",
       "      <th>eggim_square</th>\n",
       "      <th>landmark</th>\n",
       "      <th>image_directory</th>\n",
       "      <th>patient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[218, 113, 442, 338]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ii. distal body in anteversion</td>\n",
       "      <td>../2025-01_EGGIM_Dataset3/20240117160000847.jpg</td>\n",
       "      <td>PT002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[213, 228, 438, 452]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ix. distal lesser curvature in retroflexion</td>\n",
       "      <td>../2025-01_EGGIM_Dataset3/20240117160333928.jpg</td>\n",
       "      <td>PT002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[190, 231, 415, 455]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ix. distal lesser curvature in retroflexion</td>\n",
       "      <td>../2025-01_EGGIM_Dataset3/20240117160406482.jpg</td>\n",
       "      <td>PT002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[208, 235, 432, 460]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>x. upper body in retroflexion</td>\n",
       "      <td>../2025-01_EGGIM_Dataset3/20240117160431270.jpg</td>\n",
       "      <td>PT002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[314, 153, 539, 378]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>vii. proximal antrum - greater curvature/poste...</td>\n",
       "      <td>../2025-01_EGGIM_Dataset3/20240119123159483.jpg</td>\n",
       "      <td>PT003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>[328, 212, 552, 436]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ix. distal lesser curvature in retroflexion</td>\n",
       "      <td>../2025-01_EGGIM_Dataset3/20241016182413017.jpg</td>\n",
       "      <td>PT086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>[323, 178, 547, 403]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>x. upper body in retroflexion</td>\n",
       "      <td>../2025-01_EGGIM_Dataset3/20241016182430546.jpg</td>\n",
       "      <td>PT086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>[277, 140, 501, 364]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>viii. incisura in retroflexion</td>\n",
       "      <td>../2025-01_EGGIM_Dataset3/20241016182711324.jpg</td>\n",
       "      <td>PT086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>[262, 161, 486, 386]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>vii. proximal antrum - greater curvature/poste...</td>\n",
       "      <td>../2025-01_EGGIM_Dataset3/20241016182746880.jpg</td>\n",
       "      <td>PT086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>[232, 106, 456, 330]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>vi. proximal antrum - lesser curvature</td>\n",
       "      <td>../2025-01_EGGIM_Dataset3/20241016182817677.jpg</td>\n",
       "      <td>PT086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>866 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     bbox  eggim_global  eggim_square  \\\n",
       "0    [218, 113, 442, 338]             0             0   \n",
       "1    [213, 228, 438, 452]             0             0   \n",
       "2    [190, 231, 415, 455]             0             0   \n",
       "3    [208, 235, 432, 460]             1             0   \n",
       "4    [314, 153, 539, 378]             0             0   \n",
       "..                    ...           ...           ...   \n",
       "861  [328, 212, 552, 436]             0             0   \n",
       "862  [323, 178, 547, 403]             0             0   \n",
       "863  [277, 140, 501, 364]             1             1   \n",
       "864  [262, 161, 486, 386]             2             2   \n",
       "865  [232, 106, 456, 330]             1             1   \n",
       "\n",
       "                                              landmark  \\\n",
       "0                       ii. distal body in anteversion   \n",
       "1          ix. distal lesser curvature in retroflexion   \n",
       "2          ix. distal lesser curvature in retroflexion   \n",
       "3                        x. upper body in retroflexion   \n",
       "4    vii. proximal antrum - greater curvature/poste...   \n",
       "..                                                 ...   \n",
       "861        ix. distal lesser curvature in retroflexion   \n",
       "862                      x. upper body in retroflexion   \n",
       "863                     viii. incisura in retroflexion   \n",
       "864  vii. proximal antrum - greater curvature/poste...   \n",
       "865             vi. proximal antrum - lesser curvature   \n",
       "\n",
       "                                     image_directory patient_id  \n",
       "0    ../2025-01_EGGIM_Dataset3/20240117160000847.jpg      PT002  \n",
       "1    ../2025-01_EGGIM_Dataset3/20240117160333928.jpg      PT002  \n",
       "2    ../2025-01_EGGIM_Dataset3/20240117160406482.jpg      PT002  \n",
       "3    ../2025-01_EGGIM_Dataset3/20240117160431270.jpg      PT002  \n",
       "4    ../2025-01_EGGIM_Dataset3/20240119123159483.jpg      PT003  \n",
       "..                                               ...        ...  \n",
       "861  ../2025-01_EGGIM_Dataset3/20241016182413017.jpg      PT086  \n",
       "862  ../2025-01_EGGIM_Dataset3/20241016182430546.jpg      PT086  \n",
       "863  ../2025-01_EGGIM_Dataset3/20241016182711324.jpg      PT086  \n",
       "864  ../2025-01_EGGIM_Dataset3/20241016182746880.jpg      PT086  \n",
       "865  ../2025-01_EGGIM_Dataset3/20241016182817677.jpg      PT086  \n",
       "\n",
       "[866 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_togas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GroupShuffleSplit, LeavePGroupsOut\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "class DatasetProcessor:\n",
    "    def __init__(self, target_directory, image_extensions=('jpg'), annotation_extensions=('json'), id_prefix_size=10):\n",
    "        self.target_directory = target_directory\n",
    "        self.image_extensions = image_extensions\n",
    "        self.annotation_extension = annotation_extensions\n",
    "        # We assume that the patient id is encoded in the first id_prefix_size numbers of each file\n",
    "        self.id_prefix_size = id_prefix_size\n",
    "        self.dataset_dictionary = self._load_file_names()\n",
    "\n",
    "    def _load_file_names(self):\n",
    "        dataset_files = sorted(os.listdir(self.target_directory))\n",
    "        json_names = [x for x in dataset_files if x.endswith('.json')]\n",
    "        image_names = [x for x in dataset_files if x not in json_names]\n",
    "        patient_ids = np.array([x[:self.id_prefix_size] for x in json_names])\n",
    "        return {pid_: [[image_ for image_ in image_names if image_.startswith(pid_)],\n",
    "                       [json_ for json_ in json_names if json_.startswith(pid_)]] for pid_ in patient_ids}\n",
    "\n",
    "    # bbox, eggim in bbox, landmark\n",
    "    def process_json(self, directory):\n",
    "        with open(directory, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        dict_parameters = {}\n",
    "        for instance in data['instances']:\n",
    "            if instance['className'] == 'EGGIM in the FULL Anatomical Location':\n",
    "                dict_parameters['eggim_global'] = int(instance['attributes'][0]['name'])\n",
    "            if instance['className'] == 'EGGIM in Target Area - Square':\n",
    "                dict_parameters['eggim_square'] = int(instance['attributes'][0]['name'])\n",
    "            if instance['className'] == 'Anatomical Location':\n",
    "                dict_parameters['landmark'] = str(instance['attributes'][0]['name'])\n",
    "            if instance['className'] == 'Comments':\n",
    "                if not instance['attributes']:  # check if list is empty\n",
    "                    continue\n",
    "                else:\n",
    "                    id_ = str(instance['attributes'][0]['name'])\n",
    "                    id_ = re.split(r'[ \\n]+', id_)[0]\n",
    "                    if id_.startswith('PT'):  # This is necessary to mark the patients from togas\n",
    "                        dict_parameters['patient_id'] = id_\n",
    "            if instance[\"type\"] == \"bbox\" and \"points\" in instance:\n",
    "                points = instance[\"points\"]\n",
    "                left = points[\"x1\"]\n",
    "                top = points[\"y1\"]\n",
    "                right = points[\"x2\"]\n",
    "                bottom = points[\"y2\"]\n",
    "                # print(\"x1\", left, \"y1\", top, \"x2\", right, \"y2\", bottom)\n",
    "                dict_parameters['bbox'] = np.array([math.floor(left), math.floor(top), math.floor(right), math.floor(\n",
    "                    bottom)])  # plt.imshow(np.array(image)[round(y1):round(y2), round(x1):round(x2), :])\n",
    "        return dict_parameters\n",
    "\n",
    "    def process(self, merge_eggim_square=False, merge_eggim_global=False):\n",
    "        dataset_info = []\n",
    "        for patient_id, (images, jsons) in self.dataset_dictionary.items():\n",
    "            for x, y in zip(images, jsons):\n",
    "                annotation_data = self.process_json(os.path.join(self.target_directory, y))\n",
    "                annotation_data['image_directory'] = os.path.join(self.target_directory, x)\n",
    "                if 'patient_id' not in annotation_data:\n",
    "                    annotation_data['patient_id'] = patient_id\n",
    "                dataset_info.append(annotation_data)\n",
    "        df = pd.DataFrame(dataset_info)\n",
    "        if merge_eggim_square:\n",
    "            df['eggim_square'] = df['eggim_square'].apply(lambda score: 0 if score == 0 else 1)\n",
    "        if merge_eggim_global:\n",
    "            df['eggim_global'] = df['eggim_global'].apply(lambda score: 0 if score == 0 else 1)\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def patient_wise_split(df_target,\n",
    "                           df_extra,\n",
    "                           patients_ids,\n",
    "                           internal_train_size=0.5,\n",
    "                           target_variable='eggim_square',\n",
    "                           random_state=None):\n",
    "\n",
    "        assert (0 < internal_train_size) and (internal_train_size < 1)\n",
    "        for patient_id in patients_ids:\n",
    "            test_frames_rows = df_target['patient_id'] == patient_id\n",
    "\n",
    "            df_test = df_target.loc[test_frames_rows]\n",
    "            df_temp = df_target.loc[~test_frames_rows]\n",
    "            X_temp = df_temp.drop(columns=[target_variable])\n",
    "            y_temp = df_temp[target_variable]\n",
    "            sss_temp = StratifiedShuffleSplit(n_splits=1, train_size=internal_train_size,\n",
    "                                              test_size=1. - internal_train_size, random_state=random_state)\n",
    "            train_idx, val_idx = next(sss_temp.split(X_temp, y_temp))\n",
    "\n",
    "            df_train = df_target.iloc[train_idx]\n",
    "            df_val = df_target.iloc[val_idx]\n",
    "            df_train = DatasetProcessor.augment_dataframe_stratified(df_train,\n",
    "                                                                     df_extra,\n",
    "                                                                     target_column=target_variable)\n",
    "            df_train = pd.concat([df_train, df_extra], axis=0)\n",
    "\n",
    "            yield df_train, df_val, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../configs/test_patient_ids_2.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m target_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../test_files/EGGIMazing/Dataset01\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m patient_ids \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../configs/test_patient_ids_2.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m dp \u001b[38;5;241m=\u001b[39m DatasetProcessor(target_dir)\n\u001b[1;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m dp\u001b[38;5;241m.\u001b[39mprocess()\n",
      "File \u001b[0;32m~/Desktop/tese/venv_3.10.12/lib/python3.10/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../configs/test_patient_ids_2.npy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "target_dir = '../test_files/EGGIMazing/Dataset01'\n",
    "patient_ids = np.load('../configs/test_patient_ids_2.npy', allow_pickle=True)\n",
    "dp = DatasetProcessor(target_dir)\n",
    "df = dp.process()\n",
    "\n",
    "togas_ids_boolean = np.array([x.startswith('PT') for x in df['patient_id'].values])\n",
    "df_togas = df[togas_ids_boolean].reset_index(drop=True)\n",
    "df_ipo = df[~togas_ids_boolean].reset_index(drop=True)\n",
    "\n",
    "split = dp.patient_wise_split(df_togas,\n",
    "                              df_ipo,\n",
    "                              patient_ids,\n",
    "                              internal_train_size=0.9,\n",
    "                              target_variable='eggim_square',\n",
    "                              random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bboxes = np.stack(np.array(df_togas['bbox'].values), axis=-1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pt04 = df_togas[df_togas['patient_id'] == 'PT004']\n",
    "pt24 = df_togas[df_togas['patient_id'] == 'PT024']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PT002', 'PT003', 'PT004', 'PT005', 'PT006', 'PT007', 'PT008',\n",
       "       'PT009', 'PT010', 'PT011', 'PT012', 'PT013', 'PT014', 'PT015',\n",
       "       'PT016', 'PT017', 'PT018', 'PT019', 'PT020', 'PT021', 'PT022',\n",
       "       'PT023', 'PT024', 'PT025', 'PT026', 'PT027', 'PT028', 'PT029',\n",
       "       'PT030', 'PT031', 'PT032', 'PT034', 'PT035', 'PT036', 'PT037',\n",
       "       'PT038', 'PT039', 'PT040', 'PT041', 'PT042', 'PT043', 'PT044',\n",
       "       'PT045', 'PT046', 'PT047', 'PT048', 'PT049', 'PT050', 'PT051',\n",
       "       'PT052', 'PT053'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_togas.patient_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 16:51:36.049270: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.049526: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.096861: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.097238: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.097449: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.097635: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.252618: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.252887: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.253098: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.253277: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.253452: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.253625: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.263712: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.263920: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.264116: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.264294: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.264475: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.264641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 18737 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-11-08 16:51:36.265373: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 16:51:36.265529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22453 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:02:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from etl.load_dataset import get_tf_eggim_patch_dataset\n",
    "import tensorflow as tf\n",
    "tf_test_df = get_tf_eggim_patch_dataset(pt24, num_classes=3,\n",
    "                                                preprocess_fn=tf.keras.applications.resnet.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "patient_ids = np.load('../configs/test_patient_ids_2.npy', allow_pickle=True)\n",
    "split = dp.patient_wise_split(df_togas,\n",
    "                                  df_ipo,\n",
    "                                  patient_ids,\n",
    "                                  internal_train_size=0.9,\n",
    "                                  target_variable='eggim_square',\n",
    "                                  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for fold, (df_train, df_val, df_test) in enumerate(split):\n",
    "    if patient_ids[fold] == 'PT004':\n",
    "        pt04 = df_test\n",
    "    if patient_ids[fold] == 'PT024':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('../configs/test_patient_ids.npy', allow_pickle=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['PT004', 'PT005', 'PT006', 'PT009', 'PT016', 'PT020', 'PT021',\n",
       "        'PT022'], dtype=object),\n",
       " array(['PT004', 'PT005', 'PT006', 'PT009', 'PT016', 'PT020', 'PT021',\n",
       "        'PT022', 'PT024', 'PT025', 'PT028', 'PT029', 'PT030', 'PT031',\n",
       "        'PT034', 'PT035', 'PT037', 'PT039', 'PT040', 'PT041', 'PT045',\n",
       "        'PT046', 'PT048', 'PT049', 'PT051', 'PT053'], dtype=object))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('../configs/test_patient_ids.npy', allow_pickle=True), np.load('../configs/test_patient_ids_2.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_3.10.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
